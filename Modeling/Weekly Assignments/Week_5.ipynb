{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d010a301",
   "metadata": {},
   "source": [
    "# **Week 5 - Capstone Development**\n",
    "## **Support Vector Machines**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295d939f",
   "metadata": {},
   "source": [
    "Ok so for this one, we will take the best performing dataset in the weeks leading up to this, and then check out how a support vector 'classifier'  \n",
    "\n",
    "\n",
    "Source: https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccd20a",
   "metadata": {},
   "source": [
    "### **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a8f14bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from itertools import chain, combinations\n",
    "\n",
    "# Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker  # Optional: Format y-axis labels as dollars\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "# Scikit-learn (Machine Learning)\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    cross_val_score,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    RepeatedStratifiedKFold,\n",
    "    RepeatedKFold\n",
    ")\n",
    "\n",
    "from sklearn.svm import LinearSVC, SVC, NuSVC\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error, accuracy_score, f1_score, roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, f_regression, SelectKBest\n",
    "from sklearn.linear_model import LogisticRegression, Lasso, RidgeClassifier, ElasticNet\n",
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_predict, KFold\n",
    "# Progress Tracking\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# =============================\n",
    "# Global Variables\n",
    "# =============================\n",
    "random_state = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609163e2",
   "metadata": {},
   "source": [
    "### **Dataset Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34dbdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7be12cab",
   "metadata": {},
   "source": [
    "### **Useful Functions**\n",
    "\n",
    "Here we will import functions used in previous weeks to handle our data modeling. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ed5090",
   "metadata": {},
   "source": [
    "#### **Train Test Split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d806188",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================================================================\n",
    "# Function taken from Module 3 Final Project\n",
    "# https://github.com/LeeMcFarling/Final_Project_Writeup/blob/main/Final_Project_Report.ipynb\n",
    "# ===========================================================================================\n",
    "\n",
    "def train_test_split_data(df, target_col):\n",
    "    X = df.drop(columns=target_col)\n",
    "    y = df[target_col]\n",
    "# \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "019b5b79",
   "metadata": {},
   "source": [
    "#### **Run Model Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41eabadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================================\n",
    "# Taken from Mod 3 Week 8:\n",
    "# https://github.com/waysnyder/Module-3-Assignments/blob/main/Homework_08.ipynb\n",
    "# \n",
    "# Global dataframe logic taken from mod 3 final project: \n",
    "# https://github.com/LeeMcFarling/Final_Project_Writeup/blob/main/Final_Project_Report.ipynb\n",
    "# \n",
    "# Final Function was developed in Week 2 of this Module\n",
    "# =============================================================================================\n",
    "\n",
    "def run_model_classifier(model, X_train, y_train, X_test, y_test, n_repeats=10, n_jobs=-1, run_comment=None, return_model=False, concat_results=False, **model_params):\n",
    "\n",
    "    global combined_results\n",
    "    # Remove extra key used to store error metric, if it was added to the parameter dictionary\n",
    "    if 'accuracy_found' in model_params:\n",
    "        model_params = model_params.copy()\n",
    "        model_params.pop('accuracy_found', None)  \n",
    "        \n",
    "    # Instantiate the model if a class is provided\n",
    "    if isinstance(model, type):\n",
    "        model = model(**model_params)\n",
    "    else:                                    \n",
    "        model.set_params(**model_params)    \n",
    "\n",
    "    model_name = model.__name__ if isinstance(model, type) else model.__class__.__name__ # Added because \n",
    "\n",
    "\n",
    "    # Use RepeatedStratifiedKFold for classification to preserve class distribution\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=n_repeats, random_state=42)\n",
    "    \n",
    "    # Perform 5-fold cross-validation using accuracy as the scoring metric\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=n_jobs)\n",
    "    \n",
    "    mean_cv_accuracy = np.mean(cv_scores)\n",
    "    std_cv_accuracy  = np.std(cv_scores)\n",
    "    \n",
    "    # Fit the model on the full training set\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Compute training and testing accuracy\n",
    "    train_preds    = model.predict(X_train)\n",
    "    test_preds     = model.predict(X_test)\n",
    "\n",
    "    # Normal Accuracy \n",
    "    train_accuracy = accuracy_score(y_train, train_preds)\n",
    "    test_accuracy  = accuracy_score(y_test, test_preds)\n",
    "\n",
    "    # Balanced Accuracy Metrics\n",
    "    balanced_train_accuracy = balanced_accuracy_score(y_train, train_preds)\n",
    "    balanced_test_accuracy = balanced_accuracy_score(y_test, test_preds)\n",
    "\n",
    "    results_df = pd.DataFrame([{\n",
    "        'model': model_name, \n",
    "        'model_params': model.get_params(),\n",
    "        'mean_cv_accuracy': mean_cv_accuracy,\n",
    "        'std_cv_accuracy': std_cv_accuracy,\n",
    "        'train_accuracy': train_accuracy, \n",
    "        'test_accuracy': test_accuracy,\n",
    "        'balanced_train_accuracy' : balanced_train_accuracy,\n",
    "        'balanced_test_accuracy': balanced_test_accuracy,\n",
    "        'run_comment': run_comment\n",
    "    }])\n",
    "    \n",
    "    if concat_results:\n",
    "        try:\n",
    "            combined_results = pd.concat([combined_results, results_df], ignore_index=True)\n",
    "        except NameError:\n",
    "            combined_results = results_df\n",
    "\n",
    "    return (results_df, model) if return_model else results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3da5af",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1e4b92",
   "metadata": {},
   "source": [
    "### **Data Pre-Processing**\n",
    "\n",
    "Train-test splitting our data: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4af12ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c73b0c14",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf6ffa0",
   "metadata": {},
   "source": [
    "## **Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab7bf3d",
   "metadata": {},
   "source": [
    "Let's start with a Linear Support Vector Classifier with parameters set to the same general params as our original Logistic Regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0170fd1e",
   "metadata": {},
   "source": [
    "Let's start with the Big Data Bowl Dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcc169e",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ = {\n",
    "    'class_weight' : 'balanced',        # attempt to balance dataset\n",
    "    'solver': 'saga',                   # Doc said that this solver is better for larger datasets\n",
    "    'penalty': 'l2',                    # default\n",
    "    'fit_intercept': 'True',\n",
    "    'max_iter' : 50000,                 # Iteratively increased this until Convergence Warnings went away\n",
    "    'tol': 1e-2,                        # Another convergence warning measure\n",
    "    'random_state' : 42\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "BDB_Linear_SVC_results_df = run_model_classifier(\n",
    "    LinearSVC,\n",
    "    # BDB_PCA_X_train, \n",
    "    # BDB_PCA_y_train, \n",
    "    # BDB_PCA_X_test,\n",
    "    # BDB_PCA_y_test,\n",
    "    n_repeats=5, \n",
    "    n_jobs=-1, \n",
    "    run_comment='BDB - Linear SVC', \n",
    "    return_model=False,\n",
    "    concat_results=True,\n",
    "    **params_\n",
    "    )\n",
    "\n",
    "BDB_Linear_SVC_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5fb0b7",
   "metadata": {},
   "source": [
    "And then try it on the First and Future Dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6c5b935",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_ = {\n",
    "    'class_weight' : 'balanced',        # attempt to balance dataset\n",
    "    'solver': 'saga',                   # Doc said that this solver is better for larger datasets\n",
    "    'penalty': 'l2',                    # default\n",
    "    'fit_intercept': 'True',\n",
    "    'max_iter' : 50000,                 # Iteratively increased this until Convergence Warnings went away\n",
    "    'tol': 1e-2,                        # Another convergence warning measure\n",
    "    'random_state' : 42\n",
    "\n",
    "\n",
    "}\n",
    "\n",
    "FNF_Linear_SVC_results_df = run_model_classifier(\n",
    "    LinearSVC,\n",
    "    # BDB_PCA_X_train, \n",
    "    # BDB_PCA_y_train, \n",
    "    # BDB_PCA_X_test,\n",
    "    # BDB_PCA_y_test,\n",
    "    n_repeats=5, \n",
    "    n_jobs=-1, \n",
    "    run_comment='FNF - Linear SVC - Baseline', \n",
    "    return_model=False,\n",
    "    concat_results=True,\n",
    "    **params_\n",
    "    )\n",
    "\n",
    "FNF_Linear_SVC_results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69081dd9",
   "metadata": {},
   "source": [
    "###"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfclean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
