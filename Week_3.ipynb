{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933f6a14",
   "metadata": {},
   "source": [
    "# **Week 3**\n",
    "### **Forward and Backward Feature Selection, PCA/R, PLCR**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7329e84b",
   "metadata": {},
   "source": [
    "Quick note here: \n",
    "\n",
    "Again the main task of our models and datasets is to see if we can meaningfully predict whether an injury will occur in different plays in the NFL, and then do a deep dive on which conditions are most likely to lead to those injuries. \n",
    "\n",
    "We have three datasets looking at different types of injuries in the NFL: \n",
    "- **First and Future:** Which looks at lower extremity injuries\n",
    "- **Punt Data Analytics:** Which looks at head injuries during punt plays\n",
    "- **Big Data Bowl:** Which looks at a variety of injuries in the NFL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a20d9630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os\n",
    "import time\n",
    "import math\n",
    "import io\n",
    "import zipfile\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from itertools import chain, combinations\n",
    "from joblib import Memory\n",
    "import warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "\n",
    "# Data Science Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.ticker as mticker  # Optional: Format y-axis labels as dollars\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK Learn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "491046e0",
   "metadata": {},
   "source": [
    "#### **Import Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d36509",
   "metadata": {},
   "outputs": [],
   "source": [
    "BDB_All_Plays_Model_Ready = pd.read_csv(\"BDB_All_Plays_Model_Ready.csv\") # Big Data Bowl Dataset\n",
    "PDA_Model_Ready = pd.read_csv(\"PDA_Model_Ready.csv\") # Punt Data Analytics\n",
    "FNF_Model_Ready = pd.read_csv(\"FNF_Model_Ready.csv\") # First and Future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5538d29",
   "metadata": {},
   "source": [
    "## **Forward Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "284e58cf",
   "metadata": {},
   "source": [
    "We used boiler plate forward featue selection in our previous modules, but that was specifically written for Regression. This attempts to use SKlearn's built-in functionality to tailor it for our Classification Operation. \n",
    "\n",
    "\n",
    "First, we need to filter out our numeric data from our one-hot encoded categorical data and Target variable, and then we need to feed that into a pipeline where we scale the numeric features, and then run a feature selection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "05099913",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Looked up a Standard Scaler to Log Regression here: \n",
    "# https://www.google.com/search?q=sklearn+pipeline+and+forward+feature+selection&sca_esv=fd2d5e0aca235bbf&rlz=1C5CHFA_enUS1112US1112&ei=szTtaMqHNPiq0PEP3p3x0QI&oq=sklearn+pipeline+and+forward&gs_lp=Egxnd3Mtd2l6LXNlcnAiHHNrbGVhcm4gcGlwZWxpbmUgYW5kIGZvcndhcmQqAggAMgUQIRigATIFECEYoAEyBRAhGKABMgUQIRigATIFECEYnwVIk2FQiAlYhlVwA3gBkAEAmAG9AaAB4RuqAQQwLjI4uAEDyAEA-AEBmAIfoAL_HMICChAAGLADGNYEGEfCAg0QABiABBiRAhiKBRgKwgIKEAAYgAQYQxiKBcICDhAuGIAEGLEDGNEDGMcBwgIWEC4YgAQYsQMY0QMYQxiDARjHARiKBcICExAuGIAEGLEDGNEDGEMYxwEYigXCAg0QABiABBixAxhDGIoFwgIIEAAYgAQYsQPCAgUQLhiABMICBRAAGIAEwgIOEAAYgAQYkQIYsQMYigXCAgsQABiABBiRAhiKBcICDBAAGIAEGEMYigUYCsICBhAAGBYYHsICCBAAGKIEGIkFwgIFEAAY7wXCAggQABiABBiiBMICCxAAGIAEGIYDGIoFwgIHECEYoAEYCpgDAIgGAZAGCJIHBDMuMjigB76yAbIHBDAuMji4B_EcwgcHMC4xMC4yMcgHbQ&sclient=gws-wiz-serp\n",
    "# \n",
    "# Pre-Processor was added with help from ChatGPT: \n",
    "# https://chatgpt.com/share/68ed4580-9b74-800f-b5d0-f817ffafccaa\n",
    "# ==========================================================\n",
    "\n",
    "nuniques = X.nunique(dropna=True)\n",
    "numeric_cols = nuniques.index[nuniques > 2].tolist()\n",
    "onehot_cols  = nuniques.index[nuniques == 2].tolist()\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_cols),\n",
    "    ('cat', 'passthrough', onehot_cols)\n",
    "])\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    class_weight='balanced', solver='liblinear', C=0.2,\n",
    "    penalty='l2', max_iter=2000, tol=1e-2, random_state=42\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(3, shuffle=True, random_state=42)\n",
    "\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=logreg,\n",
    "    n_features_to_select=30,   # Selecting all was yielding run times of > 1 hr\n",
    "    direction='forward',\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('sfs', sfs),\n",
    "    ('model', logreg)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42cecfc",
   "metadata": {},
   "source": [
    "And now we'll call that code that we made earlier for the Big Data Bowl Dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1e525849",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "/Users/leemcfarling/venvs/tfclean/lib/python3.12/site-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num__preSnapHomeScore', 'num__playResult', 'cat__possessionTeam_CIN', 'cat__possessionTeam_CLE', 'cat__possessionTeam_LV', 'cat__possessionTeam_WAS', 'cat__defensiveTeam_CHI', 'cat__defensiveTeam_DAL', 'cat__defensiveTeam_JAX', 'cat__defensiveTeam_LV', 'cat__defensiveTeam_NO', 'cat__defensiveTeam_NYJ', 'cat__defensiveTeam_PIT', 'cat__yardlineSide_JAX', 'cat__yardlineSide_KC', 'cat__yardlineSide_MIA', 'cat__yardlineSide_MIN', 'cat__yardlineSide_NYJ', 'cat__yardlineSide_PIT', 'cat__yardlineSide_TEN', 'cat__yardlineSide_UNK', 'cat__passResult_R', 'cat__passResult_S', 'cat__offenseFormation_JUMBO', 'cat__offenseFormation_SHOTGUN', 'cat__offenseFormation_WILDCAT', 'cat__dropBackType_DESIGNED_ROLLOUT_RIGHT', 'cat__dropBackType_DESIGNED_RUN', 'cat__dropBackType_SCRAMBLE_ROLLOUT_RIGHT', 'cat__pff_passCoverageType_Other']\n"
     ]
    }
   ],
   "source": [
    "X = BDB_All_Plays_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = BDB_All_Plays_Model_Ready['Inj_Occured']\n",
    "\n",
    "pipe.fit(X, y)\n",
    "mask = pipe.named_steps['sfs'].get_support()\n",
    "feat_names = pipe.named_steps['pre'].get_feature_names_out()\n",
    "bdb_forward_selected = [f for f, m in zip(feat_names, mask) if m]\n",
    "print(bdb_forward_selected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b147c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bdb_forward_selected"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca348407",
   "metadata": {},
   "source": [
    "And Forward Selection for the first and Future Dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ccf21e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FNF_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = FNF_Model_Ready['Inj_Occured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "03680003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "['num__PlayerDay', 'num__Temperature', 'num__PlayerGamePlay', 'num__x', 'num__speed', 'cat__StadiumType_Outdoors', 'cat__FieldType_Synthetic', 'cat__Weather_Fog', 'cat__Weather_N/A (Indoors)', 'cat__Weather_Partly Cloudy', 'cat__Weather_Rain', 'cat__Weather_Snow', 'cat__PlayType_Field Goal', 'cat__PlayType_Kickoff', 'cat__PlayType_Pass', 'cat__PlayType_Punt', 'cat__PlayType_Rush', 'cat__PlayType_Unknown', 'cat__Position_CB', 'cat__Position_FS', 'cat__Position_G', 'cat__Position_HB', 'cat__Position_K', 'cat__Position_MLB', 'cat__Position_Missing Data', 'cat__Position_NT', 'cat__Position_P', 'cat__Position_QB', 'cat__Position_S', 'cat__Position_T']\n"
     ]
    }
   ],
   "source": [
    "X = FNF_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = FNF_Model_Ready['Inj_Occured']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "mask = pipe.named_steps['sfs'].get_support()\n",
    "feat_names = pipe.named_steps['pre'].get_feature_names_out()\n",
    "fnf_forward_selected = [f for f, m in zip(feat_names, mask) if m]  \n",
    "print()  \n",
    "print(fnf_forward_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8255a74a",
   "metadata": {},
   "source": [
    "And then for the Punt Data Analytics Dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "42651077",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = PDA_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = PDA_Model_Ready['Inj_Occured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9fb5dd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num__yardline_100', 'cat__Game_Day_Wednesday', 'cat__Start_Time_13:00', 'cat__Start_Time_17:00', 'cat__Start_Time_20:00', 'cat__Visit_Team_Atlanta Falcons', 'cat__Visit_Team_Cleveland Browns', 'cat__Visit_Team_Detroit Lions', 'cat__Visit_Team_Houston Texans', 'cat__Visit_Team_Indianapolis Colts', 'cat__Visit_Team_Los Angeles Rams', 'cat__Visit_Team_Miami Dolphins', 'cat__Visit_Team_Minnesota Vikings', 'cat__Visit_Team_New England Patriots', 'cat__Visit_Team_New Orleans Saints', 'cat__Visit_Team_New York Jets', 'cat__Visit_Team_Philadelphia Eagles', 'cat__Visit_Team_Pittsburgh Steelers', 'cat__Visit_Team_Seattle Seahawks', 'cat__Visit_Team_Tampa Bay Buccaneers', 'cat__Visit_Team_Washington Redskins', 'cat__StadiumType_Outdoors', 'cat__GameWeather_Fog', 'cat__GameWeather_N/A (Indoors)', 'cat__GameWeather_Rain', 'cat__GameWeather_Snow', 'cat__month_February', 'cat__month_November', 'cat__month_October', 'cat__month_September']\n"
     ]
    }
   ],
   "source": [
    "X = PDA_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = PDA_Model_Ready['Inj_Occured']\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "mask = pipe.named_steps['sfs'].get_support()\n",
    "feat_names = pipe.named_steps['pre'].get_feature_names_out()\n",
    "pda_forward_selected = [f for f, m in zip(feat_names, mask) if m]\n",
    "print(pda_forward_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b45c8e0",
   "metadata": {},
   "source": [
    "#### **Final Forward - Selected Datasets**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fced41",
   "metadata": {},
   "source": [
    "We'll filter these and then use them in future weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f1090d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def list_strip(names):\n",
    "    return [re.sub(r'^[^_]+__', '', n) for n in names]\n",
    "\n",
    "\n",
    "bdb_cols_clean = list_strip(bdb_forward_selected)\n",
    "pda_cols_clean = list_strip(pda_forward_selected)\n",
    "fnf_cols_clean = list_strip(fnf_forward_selected)\n",
    "\n",
    "# now subset with cleaned names\n",
    "BDB_Forward_Features = BDB_All_Plays_Model_Ready[bdb_cols_clean]\n",
    "PDA_Forward_Features = PDA_Model_Ready[pda_cols_clean]\n",
    "FNF_Forward_Features = FNF_Model_Ready[fnf_cols_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d4b978",
   "metadata": {},
   "source": [
    "# **Backward Feature Selection**\n",
    "\n",
    "Now we'll do a similar thing only we'll reverse the direction. We'll start with the code we had from earlier, just flipping the direction in the sequential feature selector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6aad440c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================================\n",
    "# Looked up a Standard Scaler to Log Regression here: \n",
    "# https://www.google.com/search?q=sklearn+pipeline+and+forward+feature+selection&sca_esv=fd2d5e0aca235bbf&rlz=1C5CHFA_enUS1112US1112&ei=szTtaMqHNPiq0PEP3p3x0QI&oq=sklearn+pipeline+and+forward&gs_lp=Egxnd3Mtd2l6LXNlcnAiHHNrbGVhcm4gcGlwZWxpbmUgYW5kIGZvcndhcmQqAggAMgUQIRigATIFECEYoAEyBRAhGKABMgUQIRigATIFECEYnwVIk2FQiAlYhlVwA3gBkAEAmAG9AaAB4RuqAQQwLjI4uAEDyAEA-AEBmAIfoAL_HMICChAAGLADGNYEGEfCAg0QABiABBiRAhiKBRgKwgIKEAAYgAQYQxiKBcICDhAuGIAEGLEDGNEDGMcBwgIWEC4YgAQYsQMY0QMYQxiDARjHARiKBcICExAuGIAEGLEDGNEDGEMYxwEYigXCAg0QABiABBixAxhDGIoFwgIIEAAYgAQYsQPCAgUQLhiABMICBRAAGIAEwgIOEAAYgAQYkQIYsQMYigXCAgsQABiABBiRAhiKBcICDBAAGIAEGEMYigUYCsICBhAAGBYYHsICCBAAGKIEGIkFwgIFEAAY7wXCAggQABiABBiiBMICCxAAGIAEGIYDGIoFwgIHECEYoAEYCpgDAIgGAZAGCJIHBDMuMjigB76yAbIHBDAuMji4B_EcwgcHMC4xMC4yMcgHbQ&sclient=gws-wiz-serp\n",
    "# \n",
    "# Pre-Processor was added with help from ChatGPT: \n",
    "# https://chatgpt.com/share/68ed4580-9b74-800f-b5d0-f817ffafccaa\n",
    "# ==========================================================\n",
    "\n",
    "nuniques = X.nunique(dropna=True)\n",
    "numeric_cols = nuniques.index[nuniques > 2].tolist()\n",
    "onehot_cols  = nuniques.index[nuniques == 2].tolist()\n",
    "\n",
    "pre = ColumnTransformer([\n",
    "    ('num', StandardScaler(), numeric_cols),\n",
    "    ('cat', 'passthrough', onehot_cols)\n",
    "])\n",
    "\n",
    "logreg = LogisticRegression(\n",
    "    class_weight='balanced', solver='liblinear',\n",
    "    penalty='l2', max_iter=50_000, tol=1e-2, random_state=42\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(3, shuffle=True, random_state=42)\n",
    "\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=logreg,\n",
    "    n_features_to_select='auto',\n",
    "    direction='backward',\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('sfs', sfs),\n",
    "    ('model', logreg)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56d4a69",
   "metadata": {},
   "source": [
    "And then we'll call that for the Big Data Bowl set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448d51e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = BDB_All_Plays_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = BDB_All_Plays_Model_Ready['Inj_Occured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8d5af4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num__down', 'num__yardlineNumber', 'num__preSnapHomeScore', 'num__penaltyYards', 'num__playResult', 'num__absoluteYardlineNumber', 'cat__foul_on_play', 'cat__possessionTeam_BAL', 'cat__possessionTeam_BUF', 'cat__possessionTeam_CAR', 'cat__possessionTeam_CHI', 'cat__possessionTeam_CLE', 'cat__possessionTeam_DAL', 'cat__possessionTeam_DET', 'cat__possessionTeam_MIA', 'cat__possessionTeam_NE', 'cat__possessionTeam_SEA', 'cat__possessionTeam_WAS', 'cat__defensiveTeam_ATL', 'cat__defensiveTeam_BAL', 'cat__defensiveTeam_CHI', 'cat__defensiveTeam_CLE', 'cat__defensiveTeam_GB', 'cat__defensiveTeam_JAX', 'cat__defensiveTeam_KC', 'cat__defensiveTeam_LAC', 'cat__defensiveTeam_LV', 'cat__defensiveTeam_MIA', 'cat__defensiveTeam_NO', 'cat__defensiveTeam_NYJ', 'cat__defensiveTeam_PIT', 'cat__defensiveTeam_SF', 'cat__yardlineSide_CHI', 'cat__yardlineSide_DAL', 'cat__yardlineSide_DET', 'cat__yardlineSide_GB', 'cat__yardlineSide_JAX', 'cat__yardlineSide_KC', 'cat__yardlineSide_LV', 'cat__yardlineSide_MIA', 'cat__yardlineSide_MIN', 'cat__yardlineSide_NE', 'cat__yardlineSide_NYJ', 'cat__yardlineSide_PHI', 'cat__yardlineSide_PIT', 'cat__yardlineSide_SEA', 'cat__yardlineSide_SF', 'cat__yardlineSide_TEN', 'cat__yardlineSide_WAS', 'cat__passResult_I', 'cat__passResult_R', 'cat__passResult_S', 'cat__offenseFormation_I_FORM', 'cat__offenseFormation_JUMBO', 'cat__offenseFormation_SHOTGUN', 'cat__offenseFormation_WILDCAT', 'cat__dropBackType_DESIGNED_ROLLOUT_RIGHT', 'cat__dropBackType_DESIGNED_RUN', 'cat__dropBackType_SCRAMBLE_ROLLOUT_LEFT', 'cat__dropBackType_SCRAMBLE_ROLLOUT_RIGHT', 'cat__pff_passCoverageType_Other', 'cat__pff_passCoverageType_Zone']\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "mask = pipe.named_steps['sfs'].get_support()\n",
    "feat_names = pipe.named_steps['pre'].get_feature_names_out()\n",
    "bdb_backward_selected = [f for f, m in zip(feat_names, mask) if m]\n",
    "print(bdb_backward_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd38a083",
   "metadata": {},
   "source": [
    "And then the first and future set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d546e8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FNF_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = FNF_Model_Ready['Inj_Occured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abcc9326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num__PlayerDay', 'num__Temperature', 'num__PlayerGamePlay', 'num__x', 'num__speed', 'cat__StadiumType_Outdoors', 'cat__FieldType_Synthetic', 'cat__Weather_Fog', 'cat__Weather_N/A (Indoors)', 'cat__Weather_Partly Cloudy', 'cat__Weather_Rain', 'cat__Weather_Snow', 'cat__PlayType_Kickoff', 'cat__PlayType_Pass', 'cat__PlayType_Punt', 'cat__PlayType_Rush', 'cat__Position_CB', 'cat__Position_G', 'cat__Position_HB', 'cat__Position_K', 'cat__Position_NT', 'cat__Position_P', 'cat__Position_QB', 'cat__Position_S']\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "mask = pipe.named_steps['sfs'].get_support()\n",
    "feat_names = pipe.named_steps['pre'].get_feature_names_out()\n",
    "fnf_forward_selected = [f for f, m in zip(feat_names, mask) if m]\n",
    "print(fnf_backward_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3db259",
   "metadata": {},
   "source": [
    "and then the punt data analytics set: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "19573c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = PDA_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = PDA_Model_Ready['Inj_Occured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aa6b59e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['num__yardline_100', 'cat__Game_Day_Wednesday', 'cat__Start_Time_13:00', 'cat__Start_Time_14:00', 'cat__Start_Time_15:00', 'cat__Start_Time_16:00', 'cat__Start_Time_19:00', 'cat__Start_Time_20:00', 'cat__Visit_Team_Atlanta Falcons', 'cat__Visit_Team_Cincinnati Bengals', 'cat__Visit_Team_Cleveland Browns', 'cat__Visit_Team_Detroit Lions', 'cat__Visit_Team_Houston Texans', 'cat__Visit_Team_Los Angeles Rams', 'cat__Visit_Team_Miami Dolphins', 'cat__Visit_Team_Minnesota Vikings', 'cat__Visit_Team_New England Patriots', 'cat__Visit_Team_New Orleans Saints', 'cat__Visit_Team_New York Jets', 'cat__Visit_Team_Pittsburgh Steelers', 'cat__Visit_Team_San Francisco 49ers', 'cat__Visit_Team_Seattle Seahawks', 'cat__Visit_Team_Tampa Bay Buccaneers', 'cat__Visit_Team_Washington Redskins', 'cat__StadiumType_Outdoors', 'cat__GameWeather_Fog', 'cat__GameWeather_N/A (Indoors)', 'cat__GameWeather_Rain', 'cat__GameWeather_Snow', 'cat__month_December', 'cat__month_February', 'cat__month_November', 'cat__month_October', 'cat__month_September']\n"
     ]
    }
   ],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "mask = pipe.named_steps['sfs'].get_support()\n",
    "feat_names = pipe.named_steps['pre'].get_feature_names_out()\n",
    "pda_backward_selected = [f for f, m in zip(feat_names, mask) if m]\n",
    "print(pda_backward_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e75ab0",
   "metadata": {},
   "source": [
    "And let's throw em into dataframes as well: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807181be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "bdb_back_cols_clean = list_strip(bdb_backward_selected)\n",
    "pda_back_cols_clean = list_strip(pda_backward_selected)\n",
    "fnf_back_cols_clean = list_strip(fnf_backward_selected)\n",
    "\n",
    "BDB_back_Features = BDB_All_Plays_Model_Ready[bdb_back_cols_clean]\n",
    "PDA_back_Features = PDA_Model_Ready[pda_back_cols_clean]\n",
    "FNF_back_Features = FNF_Model_Ready[fnf_back_cols_clean]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88aecb6a",
   "metadata": {},
   "source": [
    "_____\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c69d8b3",
   "metadata": {},
   "source": [
    "## **Principle Component ~~Regression~~ Classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fd9213",
   "metadata": {},
   "source": [
    "The idea here is to use PCA on the numeric columns, concatenate those back with the one-hot encodings and the run a logistic regression on the resulting dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b7b838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- split columns by cardinality\n",
    "nuniques = X.nunique(dropna=True)\n",
    "numeric_cols = nuniques.index[nuniques > 2].tolist()\n",
    "onehot_cols  = nuniques.index[nuniques == 2].tolist()\n",
    "\n",
    "# --- preprocess: scale -> PCA for numeric, passthrough one-hots\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num_pca', Pipeline([\n",
    "            ('scale', StandardScaler()),\n",
    "            ('pca', PCA(n_components=0.95,            # keep 95% variance (or set an int like 30)\n",
    "                        svd_solver='full',      \n",
    "                        random_state=42))\n",
    "        ]), numeric_cols),\n",
    "        ('cat', 'passthrough', onehot_cols)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# --- base model\n",
    "logreg = LogisticRegression(\n",
    "    class_weight='balanced', solver='saga',\n",
    "    penalty='l2', C=0.2, tol=1e-2, max_iter=2000, random_state=42\n",
    ")\n",
    "\n",
    "# --- SFS over the concatenated (PCA comps + one-hots)\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "sfs = SequentialFeatureSelector(\n",
    "    estimator=logreg,\n",
    "    n_features_to_select=30,          # cap for speed; adjust/try 'auto' later\n",
    "    direction='forward',\n",
    "    scoring='roc_auc',\n",
    "    cv=cv,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# --- full pipeline: preprocess → SFS → model\n",
    "cache = Memory(\"./sk_cache\", verbose=0)            # speeds up repeated preprocessing\n",
    "pipe = Pipeline([\n",
    "    ('pre', pre),\n",
    "    ('sfs', sfs),\n",
    "    ('model', logreg)\n",
    "], memory=cache)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc524f0a",
   "metadata": {},
   "source": [
    "And then let's call that and get the new features: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ad1b39",
   "metadata": {},
   "source": [
    "For the big data bowl: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641dc1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = BDB_All_Plays_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = BDB_All_Plays_Model_Ready['Inj_Occured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b14578db",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "mask = pipe.named_steps['sfs'].get_support()\n",
    "feat_names = pipe.named_steps['pre'].get_feature_names_out()   # names include 'num_pca__pca0', 'cat__Feature_X'\n",
    "bdb_pca_selected = [f for f, m in zip(feat_names, mask) if m]\n",
    "print(bdb_pca_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beac783a",
   "metadata": {},
   "source": [
    "and for the first and future: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f798618",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = FNF_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = FNF_Model_Ready['Inj_Occured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f780789",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "    \n",
    "mask = pipe.named_steps['sfs'].get_support()\n",
    "feat_names = pipe.named_steps['pre'].get_feature_names_out()\n",
    "fnf_pca_selected = [f for f, m in zip(feat_names, mask) if m]\n",
    "print(fnf_pca_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6fa949",
   "metadata": {},
   "source": [
    "punt data analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da19290",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = PDA_Model_Ready.drop(columns=['Inj_Occured'])\n",
    "y = PDA_Model_Ready['Inj_Occured']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb791f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "    pipe.fit(X, y)\n",
    "\n",
    "mask = pipe.named_steps['sfs'].get_support()\n",
    "feat_names = pipe.named_steps['pre'].get_feature_names_out()\n",
    "pda_backward_selected = [f for f, m in zip(feat_names, mask) if m]\n",
    "print(pda_backward_selected)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfclean",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
